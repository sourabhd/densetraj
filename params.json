{"name":"Densetraj","tagline":"On trajectory based features and video threads for action recognition","body":"On trajectory based features and video threads for action recognition\r\n=====================================================================\r\n\r\n* *Author:* Sourabh Daptardar (saurabh.daptardar@gmail.com)\r\n\r\n* *Advisor:* [Dr. Minh Hoai Nguyen](http://www3.cs.stonybrook.edu/~minhhoai/index.html)\r\n\r\n* *Institute:* Stony Brook University\r\n\r\n* *Problem Domain:* Action Recognition \r\n\r\n* *Description:* The project aims to study features and learning methods based on trajectory [Wang et al] for action recognition. In particular, the question of automatically selecting video threads and its impact on action recognition performance was investigated. This code was developed for the experimentations described in the project report.\r\n \r\n This work was done as part of MS (Computer Science) project at SUNY, Stony Brook, in Fall 2014 sememster.\r\n\r\n* *Keywords:* computer vision, video processing, machine learning, action recognition\r\n\r\n* *Report:* https://github.com/sourabhd/densetraj/blob/master/docs/ProjectReport.pdf\r\n\r\n* *Dependencies:*\r\n   1. [Improved trajectory features](https://lear.inrialpes.fr/people/wang/improved_trajectories)\r\n   2. [VLFeat](http://www.vlfeat.org/)\r\n  \r\n* *Dataset:* [Hollywood2](http://www.di.ens.fr/~laptev/actions/hollywood2/)\r\n\r\n* *License:* GPLv3\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}